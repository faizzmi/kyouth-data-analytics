{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13f6a4c8",
   "metadata": {
    "id": "13f6a4c8"
   },
   "source": [
    "# Guided Practice Module 3: Data Preparation with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49599595",
   "metadata": {
    "id": "49599595"
   },
   "source": [
    "## üéØYour Mission\n",
    "\n",
    "You‚Äôve been hired by a marketing analytics team for a retail company. They are planning a new customer loyalty program and need clean, analysis-ready data to identify purchase patterns and segment customers effectively.\n",
    "\n",
    "You are given two datasets\n",
    "- customer_retail.csv\n",
    "- transactions_retail.csv\n",
    "\n",
    "Your first task is to prepare both datasets for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fc2e01",
   "metadata": {
    "id": "c2fc2e01"
   },
   "source": [
    "By working through this problem, you will apply the following learning objectives from Lessons 3A - 3E:\n",
    "- Learn how to handle missing data effectively.\n",
    "- Perform data manipulation and transformation using Python.\n",
    "- Join datasets for a comprehensive analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b60d81a",
   "metadata": {
    "id": "8b60d81a"
   },
   "source": [
    "## üí≠Apply #AlgoThinking\n",
    "\n",
    "Before diving into the data, let's start by listing down what are the steps you will be taking to handle the this task. (Include atleast 5 steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5972e486",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T09:21:04.144687Z",
     "start_time": "2025-09-18T09:21:04.136737Z"
    },
    "id": "5972e486"
   },
   "outputs": [],
   "source": [
    "# load and inspect the data\n",
    "# handle missing data\n",
    "# clean and transform data\n",
    "# join dataset\n",
    "# last check and save clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d654a89",
   "metadata": {
    "id": "8d654a89"
   },
   "source": [
    "## üí°Some helpful tips while you code:\n",
    "\n",
    "You can use the cheatsheet to support you in the process of coding. You may also consider answering the following specific questions that will help you in the process:\n",
    "\n",
    "**1. Handling Missing Data:**\n",
    "- What columns contain missing values?\n",
    "- Should we remove rows with missing values or fill them with a specific value?\n",
    "- What imputation method (mean, median, mode) should we use?\n",
    "\n",
    "**2. Data Manipulation & Transformation:**\n",
    "- Are there any incorrect data types that need conversion?\n",
    "- Do we need to create new columns for better analysis (e.g., total spend per customer)?\n",
    "- How can we standardize categorical data for consistency?\n",
    "\n",
    "**3. Data Joining:**\n",
    "- What is the common key to merge the datasets?\n",
    "- What type of join (inner, left, right, full) should be used?\n",
    "- How do we ensure there are no duplicate records post-merge?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af57f543",
   "metadata": {
    "id": "af57f543"
   },
   "source": [
    "## üõ†Ô∏èYour Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "J6A4hOCYbtn-",
   "metadata": {
    "id": "J6A4hOCYbtn-"
   },
   "source": [
    "Import the relevant Python libraries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "d57fa2c2",
   "metadata": {
    "id": "d57fa2c2",
    "ExecuteTime": {
     "end_time": "2025-09-19T03:13:16.488707Z",
     "start_time": "2025-09-19T03:13:15.260347Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from odbc import dataError\n",
    "from tomlkit import value"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "To3SlU1TiAWw",
   "metadata": {
    "id": "To3SlU1TiAWw"
   },
   "source": [
    "Load both datasets"
   ]
  },
  {
   "cell_type": "code",
   "id": "45cccb58",
   "metadata": {
    "id": "45cccb58",
    "ExecuteTime": {
     "end_time": "2025-09-19T03:19:07.380114Z",
     "start_time": "2025-09-19T03:19:07.345264Z"
    }
   },
   "source": [
    "customer = pd.read_csv(\"customer_retail.csv\")\n",
    "customer.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   id  age  gender  income   education region loyalty_status  \\\n",
       "0   1   27    Male   40682    Bachelor   East           Gold   \n",
       "1   2   29    Male   15317     Masters   West        Regular   \n",
       "2   3   37    Male   38849    Bachelor   West         Silver   \n",
       "3   4   30    Male   11568  HighSchool  South        Regular   \n",
       "4   5   31  Female   46952     College  North        Regular   \n",
       "\n",
       "  purchase_frequency  purchase_amount product_category  promotion_usage  \\\n",
       "0           frequent            18249            Books                0   \n",
       "1               rare             4557         Clothing                1   \n",
       "2               rare            11822         Clothing                0   \n",
       "3           frequent             4098             Food                0   \n",
       "4         occasional            19685         Clothing                1   \n",
       "\n",
       "   satisfaction_score  \n",
       "0                 6.0  \n",
       "1                 6.0  \n",
       "2                 6.0  \n",
       "3                 7.0  \n",
       "4                 5.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>income</th>\n",
       "      <th>education</th>\n",
       "      <th>region</th>\n",
       "      <th>loyalty_status</th>\n",
       "      <th>purchase_frequency</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>product_category</th>\n",
       "      <th>promotion_usage</th>\n",
       "      <th>satisfaction_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>Male</td>\n",
       "      <td>40682</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>East</td>\n",
       "      <td>Gold</td>\n",
       "      <td>frequent</td>\n",
       "      <td>18249</td>\n",
       "      <td>Books</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>Male</td>\n",
       "      <td>15317</td>\n",
       "      <td>Masters</td>\n",
       "      <td>West</td>\n",
       "      <td>Regular</td>\n",
       "      <td>rare</td>\n",
       "      <td>4557</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>38849</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>West</td>\n",
       "      <td>Silver</td>\n",
       "      <td>rare</td>\n",
       "      <td>11822</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>Male</td>\n",
       "      <td>11568</td>\n",
       "      <td>HighSchool</td>\n",
       "      <td>South</td>\n",
       "      <td>Regular</td>\n",
       "      <td>frequent</td>\n",
       "      <td>4098</td>\n",
       "      <td>Food</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>Female</td>\n",
       "      <td>46952</td>\n",
       "      <td>College</td>\n",
       "      <td>North</td>\n",
       "      <td>Regular</td>\n",
       "      <td>occasional</td>\n",
       "      <td>19685</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "03522a1e-4972-46f4-a568-fa90c1d339c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T03:19:08.180746Z",
     "start_time": "2025-09-19T03:19:08.149691Z"
    }
   },
   "source": [
    "transactions = pd.read_csv(\"transactions_retail.csv\")\n",
    "transactions.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    id  transaction_id transaction_date payment_method  total_spent  \\\n",
       "0  247               1        01/1/2023         PayPal        608.0   \n",
       "1  727               2        02/1/2023           Cash        193.0   \n",
       "2  614               3        03/1/2023         PayPal        815.0   \n",
       "3   56               4        04/1/2023         PayPal        885.0   \n",
       "4  268               5        05/1/2023         PayPal         92.0   \n",
       "\n",
       "   discount_applied  items_purchased return_status  \n",
       "0             180.0                1     No Return  \n",
       "1             112.0                1      Returned  \n",
       "2              56.0                6      Returned  \n",
       "3              86.0                3     No Return  \n",
       "4             101.0                9     No Return  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>total_spent</th>\n",
       "      <th>discount_applied</th>\n",
       "      <th>items_purchased</th>\n",
       "      <th>return_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>247</td>\n",
       "      <td>1</td>\n",
       "      <td>01/1/2023</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>608.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1</td>\n",
       "      <td>No Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>727</td>\n",
       "      <td>2</td>\n",
       "      <td>02/1/2023</td>\n",
       "      <td>Cash</td>\n",
       "      <td>193.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Returned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>614</td>\n",
       "      <td>3</td>\n",
       "      <td>03/1/2023</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>815.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6</td>\n",
       "      <td>Returned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>04/1/2023</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>885.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>3</td>\n",
       "      <td>No Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>268</td>\n",
       "      <td>5</td>\n",
       "      <td>05/1/2023</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>92.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>9</td>\n",
       "      <td>No Return</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T03:19:08.863789Z",
     "start_time": "2025-09-19T03:19:08.845398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Customer Retail Tables Info\\n\", customer.info())\n",
    "print(\"\\n\")\n",
    "print(\"Transactions Retail Tables Info\\n\", customer.info())"
   ],
   "id": "1fadf1a7b0f62cc7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   id                  1000 non-null   int64  \n",
      " 1   age                 1000 non-null   int64  \n",
      " 2   gender              1000 non-null   object \n",
      " 3   income              1000 non-null   int64  \n",
      " 4   education           997 non-null    object \n",
      " 5   region              1000 non-null   object \n",
      " 6   loyalty_status      1000 non-null   object \n",
      " 7   purchase_frequency  994 non-null    object \n",
      " 8   purchase_amount     1000 non-null   int64  \n",
      " 9   product_category    1000 non-null   object \n",
      " 10  promotion_usage     1000 non-null   int64  \n",
      " 11  satisfaction_score  993 non-null    float64\n",
      "dtypes: float64(1), int64(5), object(6)\n",
      "memory usage: 93.9+ KB\n",
      "Customer Retail Tables Info\n",
      " None\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   id                  1000 non-null   int64  \n",
      " 1   age                 1000 non-null   int64  \n",
      " 2   gender              1000 non-null   object \n",
      " 3   income              1000 non-null   int64  \n",
      " 4   education           997 non-null    object \n",
      " 5   region              1000 non-null   object \n",
      " 6   loyalty_status      1000 non-null   object \n",
      " 7   purchase_frequency  994 non-null    object \n",
      " 8   purchase_amount     1000 non-null   int64  \n",
      " 9   product_category    1000 non-null   object \n",
      " 10  promotion_usage     1000 non-null   int64  \n",
      " 11  satisfaction_score  993 non-null    float64\n",
      "dtypes: float64(1), int64(5), object(6)\n",
      "memory usage: 93.9+ KB\n",
      "Transactions Retail Tables Info\n",
      " None\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "id": "_BtCZ3bu0CEE",
   "metadata": {
    "id": "_BtCZ3bu0CEE"
   },
   "source": [
    "###Part 1: Handling Missing Data\n",
    "\n",
    "1) Handle the missing data for both datasets\n",
    "\n",
    "üí°Tip: Use print( ) to display the missing data for each dataset to identify which columns need cleaning."
   ]
  },
  {
   "cell_type": "code",
   "id": "c1ea7c77",
   "metadata": {
    "id": "c1ea7c77",
    "ExecuteTime": {
     "end_time": "2025-09-19T03:19:11.123013Z",
     "start_time": "2025-09-19T03:19:11.115780Z"
    }
   },
   "source": [
    "# total missing data in each column\n",
    "print(\"Missing data in customer_retail table\\n\", customer.isnull().sum())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data in customer_retail table\n",
      " id                    0\n",
      "age                   0\n",
      "gender                0\n",
      "income                0\n",
      "education             3\n",
      "region                0\n",
      "loyalty_status        0\n",
      "purchase_frequency    6\n",
      "purchase_amount       0\n",
      "product_category      0\n",
      "promotion_usage       0\n",
      "satisfaction_score    7\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "a9159685-02f5-455c-88f6-0253a58fc920",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T03:19:12.750886Z",
     "start_time": "2025-09-19T03:19:12.742861Z"
    }
   },
   "source": [
    "# total missing data in each column\n",
    "print(\"Missing data in transaction_retail table\\n\", transactions.isnull().sum())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data in transaction_retail table\n",
      " id                   0\n",
      "transaction_id       0\n",
      "transaction_date     0\n",
      "payment_method       0\n",
      "total_spent          3\n",
      "discount_applied    11\n",
      "items_purchased      0\n",
      "return_status        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T03:19:13.518077Z",
     "start_time": "2025-09-19T03:19:13.504380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print all missing data for each row\n",
    "missing_edu_value_after = customer.groupby('id')[['age', 'education']].first().reset_index()\n",
    "\n",
    "# Filter for the IDs you want\n",
    "missing_edu_value_after = missing_edu_value_after[missing_edu_value_after['id'].isin([18, 19, 20])]\n",
    "\n",
    "print(missing_edu_value_after)\n",
    "# customer = missing_edu_value_after"
   ],
   "id": "e567033da7454ee5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id  age education\n",
      "17  18   21   College\n",
      "18  19   33      None\n",
      "19  20   28      None\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T03:19:14.332098Z",
     "start_time": "2025-09-19T03:19:14.322650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print all missing data for each row\n",
    "# display(transactions[transactions.isnull().any(axis=1)])\n",
    "customer.isnull().sum()"
   ],
   "id": "c2289b8c66008cba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    0\n",
       "age                   0\n",
       "gender                0\n",
       "income                0\n",
       "education             3\n",
       "region                0\n",
       "loyalty_status        0\n",
       "purchase_frequency    6\n",
       "purchase_amount       0\n",
       "product_category      0\n",
       "promotion_usage       0\n",
       "satisfaction_score    7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "id": "FcgCOu8NRDop",
   "metadata": {
    "id": "FcgCOu8NRDop"
   },
   "source": [
    "**Missing Values are present in:**\n",
    "\n",
    "1. education (categorical variable)\n",
    "2. purchase frequency (categorical variable)\n",
    "3. satisfaction score (numerical variable)\n",
    "4. total_spent (numerical variable)\n",
    "5. discount_applied (numerical variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3D8A_aRT-5",
   "metadata": {
    "id": "fa3D8A_aRT-5"
   },
   "source": [
    "2) For categorical variables, we can generally remove missing values if the **missingness is completely random and not associated with any other variable.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "KGsfrsDKRre6",
   "metadata": {
    "id": "KGsfrsDKRre6",
    "ExecuteTime": {
     "end_time": "2025-09-19T03:19:17.044842Z",
     "start_time": "2025-09-19T03:19:17.029705Z"
    }
   },
   "source": [
    "# we will focus on missing data only, if we drop certain does it will effect other data\n",
    "# untuk purchase_frequency xbole nk create sendiri dari mana2 column, so buang macam biasea\n",
    "\n",
    "customer = customer.dropna(subset=['purchase_frequency'])\n",
    "customer.isnull().sum()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    0\n",
       "age                   0\n",
       "gender                0\n",
       "income                0\n",
       "education             3\n",
       "region                0\n",
       "loyalty_status        0\n",
       "purchase_frequency    0\n",
       "purchase_amount       0\n",
       "product_category      0\n",
       "promotion_usage       0\n",
       "satisfaction_score    7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "mD4PBxPLR5OC",
   "metadata": {
    "id": "mD4PBxPLR5OC"
   },
   "source": [
    "Now, no missing value in the **purchase_frequency** column!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3DSwPLVBWhYx",
   "metadata": {
    "id": "3DSwPLVBWhYx"
   },
   "source": [
    "3) If a categorical variable is associated with another variable, we can perform conditional imputation using defined rules or value ranges.\n",
    "\n",
    "For example, we have missing values in the \"education\" column:\n",
    "\n",
    "1. Check the unique categories in the education column.\n",
    "2. Create conditions to correlate with the \"age\" column.\n",
    "3. Perform imputation"
   ]
  },
  {
   "cell_type": "code",
   "id": "zhMD88ZbW-_V",
   "metadata": {
    "id": "zhMD88ZbW-_V",
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-09-19T03:19:19.921166Z",
     "start_time": "2025-09-19T03:19:19.914200Z"
    }
   },
   "source": [
    "# untuk education since secara average populasi manusia mengamnbil certain education level boleh dianggarkan so kita bole tukar based on kategori umur for each education level\n",
    "# what to do:\n",
    "# 1. list all education level\n",
    "# 2. tengok which column yg missing\n",
    "# 3. buat conditions\n",
    "# 4. imputekan\n",
    "\n",
    "# step 1\n",
    "customer['education'].unique()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bachelor', 'Masters', 'HighSchool', 'College', nan], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "id": "R5tfmVHCXr5t",
   "metadata": {
    "id": "R5tfmVHCXr5t",
    "ExecuteTime": {
     "end_time": "2025-09-19T03:19:20.875302Z",
     "start_time": "2025-09-19T03:19:20.865002Z"
    }
   },
   "source": [
    "# step 2: check missing values\n",
    "raw_education = customer[customer['education'].isnull()]\n",
    "print(raw_education[['age','education']])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age education\n",
      "18   33       NaN\n",
      "19   28       NaN\n",
      "20   25       NaN\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T03:26:34.702071Z",
     "start_time": "2025-09-19T03:26:34.668207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# step 3\n",
    "# customer['educational_original'] = customer['education']\n",
    "\n",
    "# anggarkan missing education based on educationlevel\n",
    "def infer_education(age):\n",
    "    if pd.isnull(age):\n",
    "        return np.nan\n",
    "    elif age < 22:\n",
    "        return 'College'\n",
    "    elif 22 <= age < 30:\n",
    "        return 'Bachelor'\n",
    "    elif 30 <= age <= 40:\n",
    "        return 'Masters'\n",
    "    else:\n",
    "        return 'Bachelor'\n",
    "\n",
    "# Fill missing values\n",
    "customer['education'] = customer['education'].fillna(customer['age'].apply(infer_education))\n",
    "\n",
    "# imputed_rows = customer[customer['educational_original'].isnull()]\n",
    "# print(imputed_rows[['age', 'education']])\n",
    "# step 4\n",
    "display(customer)\n",
    "missing_value = customer['education'].isnull().sum()\n",
    "print(\"\\nNo missing value in education column\" if missing_value == 0 else \"There is \"+str(missing_value)+\" missing value in education column\")"
   ],
   "id": "c4694055d4ae2457",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       id  age  gender  income   education region loyalty_status  \\\n",
       "0       1   27    Male   40682    Bachelor   East           Gold   \n",
       "1       2   29    Male   15317     Masters   West        Regular   \n",
       "2       3   37    Male   38849    Bachelor   West         Silver   \n",
       "3       4   30    Male   11568  HighSchool  South        Regular   \n",
       "4       5   31  Female   46952     College  North        Regular   \n",
       "..    ...  ...     ...     ...         ...    ...            ...   \n",
       "995   996   30  Female   18444     College   West        Regular   \n",
       "996   997   35    Male   23348    Bachelor  South        Regular   \n",
       "997   998   24    Male    7627  HighSchool   West        Regular   \n",
       "998   999   28    Male   47063    Bachelor   West         Silver   \n",
       "999  1000   29  Female    5688    Bachelor   East        Regular   \n",
       "\n",
       "    purchase_frequency  purchase_amount product_category  promotion_usage  \\\n",
       "0             frequent            18249            Books                0   \n",
       "1                 rare             4557         Clothing                1   \n",
       "2                 rare            11822         Clothing                0   \n",
       "3             frequent             4098             Food                0   \n",
       "4           occasional            19685         Clothing                1   \n",
       "..                 ...              ...              ...              ...   \n",
       "995           frequent             8090      Electronics                0   \n",
       "996           frequent             7912            Books                1   \n",
       "997         occasional             2561      Electronics                0   \n",
       "998         occasional            19203            Books                0   \n",
       "999         occasional             1854      Electronics                1   \n",
       "\n",
       "     satisfaction_score  \n",
       "0                   6.0  \n",
       "1                   6.0  \n",
       "2                   6.0  \n",
       "3                   7.0  \n",
       "4                   5.0  \n",
       "..                  ...  \n",
       "995                 4.0  \n",
       "996                 6.0  \n",
       "997                 5.0  \n",
       "998                 6.0  \n",
       "999                 5.0  \n",
       "\n",
       "[994 rows x 12 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>income</th>\n",
       "      <th>education</th>\n",
       "      <th>region</th>\n",
       "      <th>loyalty_status</th>\n",
       "      <th>purchase_frequency</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>product_category</th>\n",
       "      <th>promotion_usage</th>\n",
       "      <th>satisfaction_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>Male</td>\n",
       "      <td>40682</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>East</td>\n",
       "      <td>Gold</td>\n",
       "      <td>frequent</td>\n",
       "      <td>18249</td>\n",
       "      <td>Books</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>Male</td>\n",
       "      <td>15317</td>\n",
       "      <td>Masters</td>\n",
       "      <td>West</td>\n",
       "      <td>Regular</td>\n",
       "      <td>rare</td>\n",
       "      <td>4557</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>38849</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>West</td>\n",
       "      <td>Silver</td>\n",
       "      <td>rare</td>\n",
       "      <td>11822</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>Male</td>\n",
       "      <td>11568</td>\n",
       "      <td>HighSchool</td>\n",
       "      <td>South</td>\n",
       "      <td>Regular</td>\n",
       "      <td>frequent</td>\n",
       "      <td>4098</td>\n",
       "      <td>Food</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>Female</td>\n",
       "      <td>46952</td>\n",
       "      <td>College</td>\n",
       "      <td>North</td>\n",
       "      <td>Regular</td>\n",
       "      <td>occasional</td>\n",
       "      <td>19685</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>30</td>\n",
       "      <td>Female</td>\n",
       "      <td>18444</td>\n",
       "      <td>College</td>\n",
       "      <td>West</td>\n",
       "      <td>Regular</td>\n",
       "      <td>frequent</td>\n",
       "      <td>8090</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>35</td>\n",
       "      <td>Male</td>\n",
       "      <td>23348</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>South</td>\n",
       "      <td>Regular</td>\n",
       "      <td>frequent</td>\n",
       "      <td>7912</td>\n",
       "      <td>Books</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>24</td>\n",
       "      <td>Male</td>\n",
       "      <td>7627</td>\n",
       "      <td>HighSchool</td>\n",
       "      <td>West</td>\n",
       "      <td>Regular</td>\n",
       "      <td>occasional</td>\n",
       "      <td>2561</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>28</td>\n",
       "      <td>Male</td>\n",
       "      <td>47063</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>West</td>\n",
       "      <td>Silver</td>\n",
       "      <td>occasional</td>\n",
       "      <td>19203</td>\n",
       "      <td>Books</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1000</td>\n",
       "      <td>29</td>\n",
       "      <td>Female</td>\n",
       "      <td>5688</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>East</td>\n",
       "      <td>Regular</td>\n",
       "      <td>occasional</td>\n",
       "      <td>1854</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>994 rows √ó 12 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No missing value in education column\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5b0c9fd4f8002c30"
  },
  {
   "cell_type": "markdown",
   "id": "BFAX9rhUl7yA",
   "metadata": {
    "id": "BFAX9rhUl7yA"
   },
   "source": [
    "Note: We will apply some of what we learned from **Lesson 2B: Intro to Conditionals** and **Lesson 2F: Functions in Python** in the following codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vjyGu3DHXEC1",
   "metadata": {
    "id": "vjyGu3DHXEC1"
   },
   "outputs": [],
   "source": "# okay?"
  },
  {
   "cell_type": "markdown",
   "id": "0V1E3Mp9lV-P",
   "metadata": {
    "id": "0V1E3Mp9lV-P"
   },
   "source": [
    "In applied data science, imputations are normally guided by established best-practice rules. However, for this exercise we will proceed with a few simplifying assumptions where we correlate age with education level.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VFhVB8x4SBpx",
   "metadata": {
    "id": "VFhVB8x4SBpx"
   },
   "source": [
    "4) When imputing for numerical columns, it is best practice to check for outliers.\n",
    "\n",
    "**Why?**\n",
    "\n",
    "Usually for numerical columns, we want to impute with either the mean or median value. Outliers can distort the *mean*, making it a poor choice for imputation. The median is more robust to outliers and gives a better central value when they are present.\n",
    "\n",
    "**What to do depending on outliers:**\n",
    "\n",
    "A) Impute with **Mean** ‚Äì if no outliers\n",
    "- If a numerical column does not have outliers, it's safe to replace missing values with the mean (average) of the column.\n",
    "\n",
    "B) Impute with **Median** ‚Äì if outliers are present\n",
    "If a numerical column has outliers, use the median instead of the mean.\n",
    "\n",
    "- The median is the middle value and is not affected by extreme values, so it gives a more reliable imputation.\n",
    "\n",
    "\n",
    "**For more information about outlier detection:** https://blog.alliedoffsets.com/beyond-the-norm-how-outlier-detection-transforms-data-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yrGB5kV9TWvT",
   "metadata": {
    "id": "yrGB5kV9TWvT"
   },
   "source": [
    "Let's check if the column with missing value (satisfaction_score) in the customers data contains outliers."
   ]
  },
  {
   "cell_type": "code",
   "id": "rSPk6xc2S25K",
   "metadata": {
    "id": "rSPk6xc2S25K",
    "ExecuteTime": {
     "end_time": "2025-09-19T03:20:24.812255Z",
     "start_time": "2025-09-19T03:20:24.778023Z"
    }
   },
   "source": [
    "def check_outlier(col):\n",
    "    Q1 = col.quantile(0.25)\n",
    "    Q3 = col.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # define lower and upper bounds\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    outliers = []\n",
    "    for value in col:\n",
    "        if value < lower_bound or value > upper_bound:\n",
    "            outliers.append(value)\n",
    "\n",
    "    return len(outliers), outliers\n",
    "\n",
    "print(customer['satisfaction_score'].describe())\n",
    "print(\"Number of outlier for statisfaction_score:\", check_outlier(customer['satisfaction_score']))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    987.000000\n",
      "mean       4.954407\n",
      "std        1.030443\n",
      "min        2.000000\n",
      "25%        4.000000\n",
      "50%        5.000000\n",
      "75%        6.000000\n",
      "max        8.000000\n",
      "Name: satisfaction_score, dtype: float64\n",
      "Number of outlier for statisfaction_score: (0, [])\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "id": "SECSr-2FTe5O",
   "metadata": {
    "id": "SECSr-2FTe5O"
   },
   "source": [
    "Check if the columns with missing value (total_spent and discount_applied) in the transactions data contain outliers."
   ]
  },
  {
   "cell_type": "code",
   "id": "24kVe5MMTKHG",
   "metadata": {
    "id": "24kVe5MMTKHG",
    "ExecuteTime": {
     "end_time": "2025-09-18T14:41:14.846915Z",
     "start_time": "2025-09-18T14:41:14.832701Z"
    }
   },
   "source": [
    "\n",
    "print(\"Number of outlier for total_spent:\", check_outlier(transactions['total_spent']))\n",
    "\n",
    "print(\"Number of outlier for discount_applied:\", check_outlier(transactions['discount_applied']))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outlier for total_spent: (0, [])\n",
      "Number of outlier for discount_applied: (3, [1850.0, 1340.0, 1333.0])\n"
     ]
    }
   ],
   "execution_count": 127
  },
  {
   "cell_type": "markdown",
   "id": "koengi310F-o",
   "metadata": {
    "id": "koengi310F-o"
   },
   "source": [
    "Now there are no outliers in satisfaction_score and total_spent, we can impute with \"mean\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "aed78962",
   "metadata": {
    "id": "aed78962",
    "ExecuteTime": {
     "end_time": "2025-09-18T14:41:17.212248Z",
     "start_time": "2025-09-18T14:41:17.184393Z"
    }
   },
   "source": [
    "def impute_data(col,method='mean'):\n",
    "    if method == 'mean':\n",
    "        return col.fillna(col.mean())\n",
    "    elif method == 'median':\n",
    "        return col.fillna(col.median())\n",
    "\n",
    "customer['satisfaction_score'] = impute_data(customer['satisfaction_score'], method='mean')\n",
    "transactions['total_spent'] = impute_data(transactions['total_spent'], method='mean')\n",
    "\n",
    "print(customer[['satisfaction_score']].isnull().sum())\n",
    "transactions[['total_spent']].isnull().sum()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "satisfaction_score    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "total_spent    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 128
  },
  {
   "cell_type": "markdown",
   "id": "az1pnrA0VKs5",
   "metadata": {
    "id": "az1pnrA0VKs5"
   },
   "source": [
    "Now, **no missing values** in satisfaction_score and total_spent columns!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3NjZ5hdhVUgJ",
   "metadata": {
    "id": "3NjZ5hdhVUgJ"
   },
   "source": [
    "There are outliers in the discount_applied column, so we can impute with \"median\""
   ]
  },
  {
   "cell_type": "code",
   "id": "eUKFGGtuVeL_",
   "metadata": {
    "id": "eUKFGGtuVeL_",
    "ExecuteTime": {
     "end_time": "2025-09-18T14:41:19.969322Z",
     "start_time": "2025-09-18T14:41:19.951913Z"
    }
   },
   "source": [
    "\n",
    "transactions['discount_applied'] = impute_data(transactions['discount_applied'], method='median')\n",
    "\n",
    "transactions[['discount_applied']].isnull().sum()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discount_applied    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 129
  },
  {
   "cell_type": "markdown",
   "id": "DhRHdt4M0h3k",
   "metadata": {
    "id": "DhRHdt4M0h3k"
   },
   "source": [
    "###Part 2: Data Manipulation and Transformation\n",
    "\n",
    "1) Now that our data have been cleaned, we can safely join the tables. Merging the datasets first, then applying further transformations, will let us review every column and make informed decisions about which custom columns to create."
   ]
  },
  {
   "cell_type": "code",
   "id": "b7130709",
   "metadata": {
    "id": "b7130709",
    "ExecuteTime": {
     "end_time": "2025-09-18T14:41:23.301709Z",
     "start_time": "2025-09-18T14:41:23.286904Z"
    }
   },
   "source": "customer.isnull().sum()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    0\n",
       "age                   0\n",
       "gender                0\n",
       "income                0\n",
       "education             0\n",
       "region                0\n",
       "loyalty_status        0\n",
       "purchase_frequency    0\n",
       "purchase_amount       0\n",
       "product_category      0\n",
       "promotion_usage       0\n",
       "satisfaction_score    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 130
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T14:41:24.824067Z",
     "start_time": "2025-09-18T14:41:24.812059Z"
    }
   },
   "cell_type": "code",
   "source": "transactions.isnull().sum()",
   "id": "48b5d35d6fd27c36",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  0\n",
       "transaction_id      0\n",
       "transaction_date    0\n",
       "payment_method      0\n",
       "total_spent         0\n",
       "discount_applied    0\n",
       "items_purchased     0\n",
       "return_status       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 131
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T14:44:15.063844Z",
     "start_time": "2025-09-18T14:44:15.040818Z"
    }
   },
   "cell_type": "code",
   "source": "merged_df = transactions.merge(customer, on='id', how='inner')\n",
   "id": "160c9662b9a07392",
   "outputs": [],
   "execution_count": 138
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T14:44:15.857564Z",
     "start_time": "2025-09-18T14:44:15.821292Z"
    }
   },
   "cell_type": "code",
   "source": "display(merged_df[merged_df.isnull().any(axis=1)])",
   "id": "18245c0ab5a53d3e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, transaction_id, transaction_date, payment_method, total_spent, discount_applied, items_purchased, return_status, age, gender, income, education, region, loyalty_status, purchase_frequency, purchase_amount, product_category, promotion_usage, satisfaction_score]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>total_spent</th>\n",
       "      <th>discount_applied</th>\n",
       "      <th>items_purchased</th>\n",
       "      <th>return_status</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>income</th>\n",
       "      <th>education</th>\n",
       "      <th>region</th>\n",
       "      <th>loyalty_status</th>\n",
       "      <th>purchase_frequency</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>product_category</th>\n",
       "      <th>promotion_usage</th>\n",
       "      <th>satisfaction_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 139
  },
  {
   "cell_type": "markdown",
   "id": "DQmVrz5J0nMl",
   "metadata": {
    "id": "DQmVrz5J0nMl"
   },
   "source": [
    "2) Now that the data has been merged, we will perform some data manipulation to create custom columns that can be useful for Exploratory Data Analysis.\n",
    "\n",
    "In this case, we will:\n",
    "\n",
    "a. Create a custom column called 'score_rank' on the 'score' column\n",
    "\n",
    "b. Apply the function to create the new column\n",
    "\n",
    "c. Display the updated DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "id": "bdaa4f27",
   "metadata": {
    "id": "bdaa4f27",
    "ExecuteTime": {
     "end_time": "2025-09-18T14:49:04.035018Z",
     "start_time": "2025-09-18T14:49:04.018869Z"
    }
   },
   "source": [
    "# b\n",
    "def rank_score(score):\n",
    "    if pd.isnull(score):\n",
    "        return 'Missing'\n",
    "    elif score < 4:\n",
    "        return 'Low'\n",
    "    elif 4 <= score < 7:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "# a and b\n",
    "merged_df['score_rank'] = merged_df['satisfaction_score'].apply(rank_score)\n",
    "\n",
    "# c\n",
    "print(merged_df[['satisfaction_score', 'score_rank']].head())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   satisfaction_score score_rank\n",
      "0                 6.0     Medium\n",
      "1                 5.0     Medium\n",
      "2                 4.0     Medium\n",
      "3                 7.0       High\n",
      "4                 4.0     Medium\n"
     ]
    }
   ],
   "execution_count": 144
  },
  {
   "cell_type": "markdown",
   "id": "7n0W3Qt2oJ8k",
   "metadata": {
    "id": "7n0W3Qt2oJ8k"
   },
   "source": [
    "3) **üë®‚Äçüë©‚Äçüëß‚ÄçüëßGroup Work:**\n",
    "\n",
    "What other custom columns can you create that could be useful for Exploratory Data Analysis?\n",
    "\n",
    "Discuss in groups and come up with some ways to do so. Share your approach and code with the rest of the class."
   ]
  },
  {
   "cell_type": "code",
   "id": "cWDXYHZ9oa42",
   "metadata": {
    "id": "cWDXYHZ9oa42",
    "ExecuteTime": {
     "end_time": "2025-09-18T14:50:15.682202Z",
     "start_time": "2025-09-18T14:50:15.647935Z"
    }
   },
   "source": [
    "# spending behaviour - Not all customers spend the same bcs some are ‚Äúbig spenders,‚Äù others are ‚Äúlow spenders.‚Äù\n",
    "merged_df['spending_category'] = pd.cut(\n",
    "    merged_df['total_spent'],\n",
    "    bins=[0, 50, 200, float('inf')],\n",
    "    labels=['Low', 'Medium', 'High']\n",
    ")\n",
    "merged_df['spending_category'].head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      High\n",
       "1    Medium\n",
       "2      High\n",
       "3      High\n",
       "4    Medium\n",
       "Name: spending_category, dtype: category\n",
       "Categories (3, object): ['Low' < 'Medium' < 'High']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 145
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T14:51:15.897794Z",
     "start_time": "2025-09-18T14:51:15.866447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Discount Usage - Discounts influence customer decisions. We want to know who buys only with discounts and who pays full price.\n",
    "merged_df['used_discount'] = merged_df['discount_applied'].apply(lambda x: 'Yes' if x > 0 else 'No')\n",
    "merged_df['discount_ratio'] = merged_df['discount_applied'] / (merged_df['total_spent'] + 1e-5)\n",
    "\n",
    "merged_df[['used_discount','discount_ratio']].head()"
   ],
   "id": "5e79bc79e06f5941",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  used_discount  discount_ratio\n",
       "0           Yes        0.296053\n",
       "1           Yes        0.580311\n",
       "2           Yes        0.068712\n",
       "3           Yes        0.097175\n",
       "4           Yes        1.097826"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>used_discount</th>\n",
       "      <th>discount_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td>0.296053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>0.580311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes</td>\n",
       "      <td>0.068712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>0.097175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1.097826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 148
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T14:51:51.209595Z",
     "start_time": "2025-09-18T14:51:51.180871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Customer Demographics - Age influences education, spending power, and product preferences.\n",
    "merged_df['age_group'] = pd.cut(\n",
    "    merged_df['age'],\n",
    "    bins=[0, 18, 30, 50, 100],\n",
    "    labels=['Teen', 'Young Adult', 'Adult', 'Senior']\n",
    ")\n",
    "merged_df['age_group'].head()"
   ],
   "id": "ff1b64e6a795fd8c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Young Adult\n",
       "1          Adult\n",
       "2    Young Adult\n",
       "3          Adult\n",
       "4    Young Adult\n",
       "Name: age_group, dtype: category\n",
       "Categories (4, object): ['Teen' < 'Young Adult' < 'Adult' < 'Senior']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 149
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T14:53:04.729253Z",
     "start_time": "2025-09-18T14:53:04.713482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Satisfaction Insights - Raw satisfaction scores (1‚Äì5) are harder to interpret. Categorizing makes analysis clearer.\n",
    "merged_df['satisfaction_flag'] = merged_df['satisfaction_score'].apply(\n",
    "    lambda x: 'High' if x >= 4 else ('Low' if x <= 2 else 'Medium')\n",
    ")\n",
    "merged_df['satisfaction_flag'].head()"
   ],
   "id": "a95baa3a13caebd8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    High\n",
       "1    High\n",
       "2    High\n",
       "3    High\n",
       "4    High\n",
       "Name: satisfaction_flag, dtype: object"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 150
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T14:55:15.134139Z",
     "start_time": "2025-09-18T14:55:15.113436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Engagement Features - Some customers shop once, others shop many times. Frequency matters as much as spending.\n",
    "customer_summary = merged_df.groupby('id').agg({\n",
    "    'total_spent': 'sum',\n",
    "    'discount_applied': 'sum',\n",
    "    'transaction_id': 'count'\n",
    "}).rename(columns={'transaction_id': 'num_transactions'})\n",
    "print(customer_summary)\n",
    "\n"
   ],
   "id": "2ace26c15588b7f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      total_spent  discount_applied  num_transactions\n",
      "id                                                   \n",
      "1           404.0              26.0                 1\n",
      "2           490.0              54.0                 1\n",
      "3           348.0               9.0                 1\n",
      "5           272.0             130.0                 1\n",
      "7           823.0              97.0                 1\n",
      "...           ...               ...               ...\n",
      "995         924.0              85.0                 1\n",
      "996         582.0             149.0                 1\n",
      "997         936.0              37.0                 1\n",
      "998         442.0             115.0                 1\n",
      "1000        601.0              25.0                 1\n",
      "\n",
      "[746 rows x 3 columns]\n"
     ]
    }
   ],
   "execution_count": 154
  },
  {
   "cell_type": "markdown",
   "id": "8rfmXgcoodK8",
   "metadata": {
    "id": "8rfmXgcoodK8"
   },
   "source": [
    "4) Let's export our merged data as merged_data_retail.csv. Please save this file - we will return to it during Lesson 4S: Sync Session to perform further Exploratory Data Analysis."
   ]
  },
  {
   "cell_type": "code",
   "id": "Fd7hWB-SaWjg",
   "metadata": {
    "id": "Fd7hWB-SaWjg",
    "ExecuteTime": {
     "end_time": "2025-09-18T14:57:16.858868Z",
     "start_time": "2025-09-18T14:57:16.830192Z"
    }
   },
   "source": [
    "merged_df.to_csv(\"retail.csv\", index=False)\n",
    "print(f\"Cleaned dataset has been successfully saved \")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset has been successfully saved \n"
     ]
    }
   ],
   "execution_count": 157
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "37fc8919b8d82d07"
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
