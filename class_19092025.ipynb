{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Outlier",
   "id": "e48f8451122550d9"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-19T09:01:34.717165Z",
     "start_time": "2025-09-19T09:01:34.711004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# different approach\n",
    "import numpy as np #to determine outliers for numerical data\n",
    "\n",
    "# Select numerical columns with missing values\n",
    "numerical_cols_with_na = customer.select_dtypes(include=np.number).columns[\n",
    "    customer.select_dtypes(include=np.number).isnull().any()\n",
    "]\n",
    "\n",
    "# Dictionary to store results\n",
    "outlier_flags = {}\n",
    "\n",
    "# Check for outliers using IQR method\n",
    "for col in numerical_cols_with_na:\n",
    "    Q1 = customer[col].quantile(0.25)\n",
    "    Q3 = customer[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Check if any values are outliers (excluding NaNs)\n",
    "    outliers_exist = ((customer[col] < lower_bound) | (customer[col] > upper_bound)).any()\n",
    "\n",
    "    # Store result\n",
    "    outlier_flags[col] = outliers_exist\n",
    "# Show True/False for each column\n",
    "print(outlier_flags)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "# Select numerical columns with missing values\n",
    "numerical_cols_with_na = transactions.select_dtypes(include=np.number).columns[\n",
    "    transactions.select_dtypes(include=np.number).isnull().any()\n",
    "]\n",
    "# Dictionary to store results\n",
    "outlier_flags = {}\n",
    "\n",
    "# Check for outliers using IQR method\n",
    "for col in numerical_cols_with_na:\n",
    "    Q1 = transactions[col].quantile(0.25)\n",
    "    Q3 = transactions[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Check if any values are outliers (excluding NaNs)\n",
    "    outliers_exist = ((transactions[col] < lower_bound) | (transactions[col] > upper_bound)).any()\n",
    "\n",
    "    # Store result\n",
    "    outlier_flags[col] = outliers_exist\n",
    "# Show True/False for each column\n",
    "print(outlier_flags)"
   ],
   "id": "5295ded184224775"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Part 2: Data Manipulation and Transformation\n",
    "Now that our data have been cleaned, we can safely join the tables. Merging the datasets first, then applying further transformations, will let us review every column and make informed decisions about which custom columns to create.\n",
    "\n",
    "2.Now that the data has been merged, we will perform some data manipulation to create custom columns that can be useful for Exploratory Data Analysis.\n",
    "In this case, we will:\n",
    "a. Create a custom column called 'score_rank' on the 'score' column\n",
    "b. Apply the function to create the new column\n",
    "c. Display the updated DataFrame"
   ],
   "id": "ae1c0ffb5faaa1ff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T10:13:02.032365Z",
     "start_time": "2025-09-19T10:13:02.026529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# choosing the merge method\n",
    "# based on this dataset there are about customer and transaction\n",
    "merged_df = customer.merge(transactions, on='id', how='inner')\n",
    "# use:\n",
    "# - inner for only customer bought something\n",
    "# - left for about customer\n",
    "# - right for about transactions\n",
    "# - outer keeps explore everything, even mismatches\n",
    "\n"
   ],
   "id": "edab3332a10d77f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T01:53:21.140845Z",
     "start_time": "2025-09-20T01:53:21.097108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "# pandas vs seaborn\n",
    "# - for seaborn, no need to download to act file\n",
    "# - for pandas, dataset must be downloaded and exist in local\n",
    "\n",
    "df=sns.load_dataset(\"iris\")\n",
    "\n",
    "df.head()"
   ],
   "id": "f3722b7fd274bd7e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T01:53:22.699424Z",
     "start_time": "2025-09-20T01:53:21.921634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import label encoder\n",
    "from sklearn import preprocessing\n",
    "# The preprocessing module contains many tools to prepare (clean/transform) data before feeding it into a Machine Learning model.\n",
    "# In ML, raw data often isnâ€™t ready for training (e.g., different scales, missing values, categorical text, etc.), so preprocessing helps make the data consistent and usable.\n",
    "\n",
    "# this code will let you, convert text categories into numbers.\n",
    "# so no need to do manually\n",
    "\n",
    "# label_encoder object knows\n",
    "\n",
    "# how to understand word labels.\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "\n",
    "# Encode labels in column 'species'.\n",
    "df['species']= label_encoder.fit_transform(df['species'])\n",
    "df['species'].unique()"
   ],
   "id": "6d45cd88ffa2487e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
