{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b8890b3",
   "metadata": {
    "id": "3b8890b3"
   },
   "source": [
    "# Lesson 3B: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a8be32",
   "metadata": {
    "id": "d4a8be32"
   },
   "source": [
    "# üéØLearning Objectives:\n",
    "\n",
    "1. Identifying and handling missing values  \n",
    "2. Identifying and removing duplicates  \n",
    "3. Export the cleaned dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I1IsEHPD-qpR",
   "metadata": {
    "id": "I1IsEHPD-qpR"
   },
   "source": [
    "# ‚ñ∂Ô∏èGetting Started\n",
    "We will get started by loading pandas and the Restaurant Transaction Dataset.csv file."
   ]
  },
  {
   "cell_type": "code",
   "id": "67e7e2c0-e0ad-4ed8-a52d-3effab95bd29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T09:20:47.688503Z",
     "start_time": "2025-09-16T09:20:47.308886Z"
    }
   },
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Restaurant_Transactions_Dataset.csv\")\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "92fde6fb-9ac5-4453-bc58-07247b871b9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T09:20:49.010634Z",
     "start_time": "2025-09-16T09:20:48.983753Z"
    }
   },
   "source": [
    "df.info()\n",
    "print(\"\\nThe missing values count:\", df.isnull().sum())\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1002 entries, 0 to 1001\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Customer_ID     1002 non-null   int64  \n",
      " 1   Food_Item       989 non-null    object \n",
      " 2   Category        1002 non-null   object \n",
      " 3   Date_of_Visit   1002 non-null   object \n",
      " 4   Time            1002 non-null   object \n",
      " 5   Weather         1002 non-null   object \n",
      " 6   Price           996 non-null    float64\n",
      " 7   Weekend         1002 non-null   object \n",
      " 8   Public_Holiday  1002 non-null   object \n",
      "dtypes: float64(1), int64(1), object(7)\n",
      "memory usage: 70.6+ KB\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "6464f34e",
   "metadata": {
    "id": "6464f34e"
   },
   "source": [
    "# 1Ô∏è‚É£ Handling Missing Values  \n",
    "\n",
    "Missing values can impact the accuracy of our analysis.\n",
    "\n",
    "### ‚úÖ What We'll Do:\n",
    "‚úîÔ∏è Identify missing values in our dataset  \n",
    "‚úîÔ∏è Visualize missing values using a DataFrame  \n",
    "‚úîÔ∏è Choose an appropriate method to handle them  (remove or impute)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f740bd8d",
   "metadata": {
    "id": "f740bd8d"
   },
   "source": [
    "### (i) Identify missing values\n",
    "We will start by identifying where is the missing value in the data set."
   ]
  },
  {
   "cell_type": "code",
   "id": "76325fdd-f92e-4287-8fee-eb5708435674",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T09:20:55.404209Z",
     "start_time": "2025-09-16T09:20:55.360624Z"
    }
   },
   "source": [
    "# axis = 0, referred to row wise\n",
    "# axis = 1, referred to column wise\n",
    "# 0,1 use as boolean\n",
    "df[df.isnull().any(axis=1)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     Customer_ID  Food_Item Category Date_of_Visit   Time  Weather    Price  \\\n",
       "27          1016        NaN     Cold    03/03/2023  22:00    Sunny  18.6800   \n",
       "41          1008        NaN      Hot    05/03/2023  20:30  Raining  19.6020   \n",
       "53          1073        NaN     Cold    27/03/2023  15:00    Sunny  12.8800   \n",
       "69          1008        NaN      Hot    30/01/2023  14:30  Raining  12.5730   \n",
       "117         1085        NaN      Hot    08/02/2023  10:00  Raining   9.6300   \n",
       "125         1003        NaN     Cold    27/02/2023  10:00    Sunny  13.1500   \n",
       "175         1008        NaN     Cold    25/03/2023  18:30    Sunny  22.5600   \n",
       "238         1038        NaN      Hot    10/01/2023  20:30  Raining   5.8680   \n",
       "334         1023        NaN     Cold    01/04/2023  15:00    Sunny  23.6040   \n",
       "402         1075        NaN      Hot    25/02/2023  18:30  Raining  10.7676   \n",
       "490         1085        NaN     Cold    31/03/2023  13:30    Sunny  12.8500   \n",
       "632         1057        NaN     Cold    11/02/2023  19:00    Sunny  19.9080   \n",
       "891         1085  Ice Cream     Cold    03/02/2023  21:30    Sunny      NaN   \n",
       "943         1084     Coffee      Hot    29/01/2023  19:30  Raining      NaN   \n",
       "948         1057        Tea      Hot    13/03/2023  13:00  Raining      NaN   \n",
       "968         1021     Coffee      Hot    19/02/2023  16:00  Raining      NaN   \n",
       "985         1055     Coffee      Hot    24/01/2023  17:30  Raining      NaN   \n",
       "988         1089        NaN      Hot    23/03/2023  14:30  Raining  16.2000   \n",
       "997         1050   Smoothie     Cold    09/03/2023  17:30    Sunny      NaN   \n",
       "\n",
       "    Weekend Public_Holiday  \n",
       "27       No             No  \n",
       "41      Yes             No  \n",
       "53       No             No  \n",
       "69       No             No  \n",
       "117      No             No  \n",
       "125      No             No  \n",
       "175     Yes             No  \n",
       "238      No             No  \n",
       "334     Yes             No  \n",
       "402     Yes            Yes  \n",
       "490      No             No  \n",
       "632     Yes             No  \n",
       "891      No             No  \n",
       "943     Yes             No  \n",
       "948      No             No  \n",
       "968     Yes             No  \n",
       "985      No            Yes  \n",
       "988      No             No  \n",
       "997      No            Yes  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Food_Item</th>\n",
       "      <th>Category</th>\n",
       "      <th>Date_of_Visit</th>\n",
       "      <th>Time</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Price</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Public_Holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cold</td>\n",
       "      <td>03/03/2023</td>\n",
       "      <td>22:00</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>18.6800</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hot</td>\n",
       "      <td>05/03/2023</td>\n",
       "      <td>20:30</td>\n",
       "      <td>Raining</td>\n",
       "      <td>19.6020</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cold</td>\n",
       "      <td>27/03/2023</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>12.8800</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hot</td>\n",
       "      <td>30/01/2023</td>\n",
       "      <td>14:30</td>\n",
       "      <td>Raining</td>\n",
       "      <td>12.5730</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hot</td>\n",
       "      <td>08/02/2023</td>\n",
       "      <td>10:00</td>\n",
       "      <td>Raining</td>\n",
       "      <td>9.6300</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cold</td>\n",
       "      <td>27/02/2023</td>\n",
       "      <td>10:00</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>13.1500</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cold</td>\n",
       "      <td>25/03/2023</td>\n",
       "      <td>18:30</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>22.5600</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hot</td>\n",
       "      <td>10/01/2023</td>\n",
       "      <td>20:30</td>\n",
       "      <td>Raining</td>\n",
       "      <td>5.8680</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>1023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cold</td>\n",
       "      <td>01/04/2023</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>23.6040</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hot</td>\n",
       "      <td>25/02/2023</td>\n",
       "      <td>18:30</td>\n",
       "      <td>Raining</td>\n",
       "      <td>10.7676</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>1085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cold</td>\n",
       "      <td>31/03/2023</td>\n",
       "      <td>13:30</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>12.8500</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>1057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cold</td>\n",
       "      <td>11/02/2023</td>\n",
       "      <td>19:00</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>19.9080</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>1085</td>\n",
       "      <td>Ice Cream</td>\n",
       "      <td>Cold</td>\n",
       "      <td>03/02/2023</td>\n",
       "      <td>21:30</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>1084</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>Hot</td>\n",
       "      <td>29/01/2023</td>\n",
       "      <td>19:30</td>\n",
       "      <td>Raining</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>1057</td>\n",
       "      <td>Tea</td>\n",
       "      <td>Hot</td>\n",
       "      <td>13/03/2023</td>\n",
       "      <td>13:00</td>\n",
       "      <td>Raining</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>1021</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>Hot</td>\n",
       "      <td>19/02/2023</td>\n",
       "      <td>16:00</td>\n",
       "      <td>Raining</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>1055</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>Hot</td>\n",
       "      <td>24/01/2023</td>\n",
       "      <td>17:30</td>\n",
       "      <td>Raining</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>1089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hot</td>\n",
       "      <td>23/03/2023</td>\n",
       "      <td>14:30</td>\n",
       "      <td>Raining</td>\n",
       "      <td>16.2000</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1050</td>\n",
       "      <td>Smoothie</td>\n",
       "      <td>Cold</td>\n",
       "      <td>09/03/2023</td>\n",
       "      <td>17:30</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "b7f23310",
   "metadata": {
    "id": "b7f23310"
   },
   "source": [
    "### (ii) Handling Missing Values - Removal\n",
    "One way to handle missing values is to remove the values. We usually do this for categorical data."
   ]
  },
  {
   "cell_type": "code",
   "id": "80c8782e-4408-4990-a728-ab221d2f2874",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T09:21:03.794883Z",
     "start_time": "2025-09-16T09:21:03.753789Z"
    }
   },
   "source": [
    "# this dropna function will drop the NaN row from table based on the specific subset\n",
    "df_cleaned1 = df.dropna(subset=['Food_Item'])\n",
    "\n",
    "print(\"Missing value after cleaning: \")\n",
    "print(df_cleaned1.isnull().sum())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value after cleaning: \n",
      "Customer_ID       0\n",
      "Food_Item         0\n",
      "Category          0\n",
      "Date_of_Visit     0\n",
      "Time              0\n",
      "Weather           0\n",
      "Price             6\n",
      "Weekend           0\n",
      "Public_Holiday    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "c98a101f",
   "metadata": {
    "id": "c98a101f"
   },
   "source": [
    "### (iii) Handling Missing Values - Imputation\n",
    "Another way to handle missing values is through imputation - usually with the mean or median. This is usually done for numerical data and which value you impute is based on which will yield you the most accurate data."
   ]
  },
  {
   "cell_type": "code",
   "id": "7542ed00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1744359637739,
     "user": {
      "displayName": "Tan Wei Jie",
      "userId": "13153057253066753068"
     },
     "user_tz": -480
    },
    "id": "7542ed00",
    "outputId": "72cc4075-c39c-40a1-d178-0225ea657691",
    "ExecuteTime": {
     "end_time": "2025-09-16T09:21:05.945036Z",
     "start_time": "2025-09-16T09:21:05.930381Z"
    }
   },
   "source": [
    "# make a copy\n",
    "df_cleaned2 = df_cleaned1.copy()\n",
    "\n",
    "# replace NaN value with mean using fillna\n",
    "# when the outliner distort the average, use median instead of mean\n",
    "df_cleaned2['Price'] = df_cleaned1['Price'].fillna(df_cleaned1['Price'].mean())\n",
    "\n",
    "print(\"Missing value after performing imputation: \")\n",
    "print(df_cleaned2['Price'].isnull().sum())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value after performing imputation: \n",
      "0\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "b81789a3",
   "metadata": {
    "id": "b81789a3"
   },
   "source": [
    "# 2Ô∏è‚É£: Identifying & Removing Duplicates\n",
    "\n",
    "Duplicate records can skew our analysis.\n",
    "\n",
    "###‚úÖ What We'll Do:\n",
    "‚úîÔ∏è **Check if there are duplicate rows**\n",
    "\n",
    "‚úîÔ∏è **Decide whether to remove them**\n",
    "\n",
    "Let's clean our data!\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "e0bbd9a1-8dea-4e50-b546-de4b46e88ef0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T09:35:15.223329Z",
     "start_time": "2025-09-16T09:35:15.172049Z"
    }
   },
   "source": [
    "df_cleaned3 = df_cleaned2.copy()\n",
    "\n",
    "# calc number of rows are duplicated\n",
    "duplicates = df_cleaned3.duplicated().sum()\n",
    "\n",
    "df_cleaned3 = df_cleaned3.drop_duplicates()\n",
    "print(f\"Number of duplicated rows: {df_cleaned3.duplicated().sum()}\")\n",
    "\n",
    "# show duplicated row\n",
    "if duplicates > 0:\n",
    "    print(\"Duplicate rows found:\")\n",
    "    display(df_cleaned2[df_cleaned2.duplicated(keep=False)])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated rows: 0\n",
      "Duplicate rows found:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     Customer_ID  Food_Item Category Date_of_Visit   Time Weather  Price  \\\n",
       "85          1023  Ice Cream     Cold    16/03/2023  12:00   Sunny  10.14   \n",
       "86          1023  Ice Cream     Cold    16/03/2023  12:00   Sunny  10.14   \n",
       "131         1075   Smoothie     Cold    03/03/2023  13:00   Sunny   6.74   \n",
       "132         1075   Smoothie     Cold    03/03/2023  13:00   Sunny   6.74   \n",
       "\n",
       "    Weekend Public_Holiday  \n",
       "85       No            Yes  \n",
       "86       No            Yes  \n",
       "131      No             No  \n",
       "132      No             No  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Food_Item</th>\n",
       "      <th>Category</th>\n",
       "      <th>Date_of_Visit</th>\n",
       "      <th>Time</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Price</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Public_Holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1023</td>\n",
       "      <td>Ice Cream</td>\n",
       "      <td>Cold</td>\n",
       "      <td>16/03/2023</td>\n",
       "      <td>12:00</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>10.14</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1023</td>\n",
       "      <td>Ice Cream</td>\n",
       "      <td>Cold</td>\n",
       "      <td>16/03/2023</td>\n",
       "      <td>12:00</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>10.14</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1075</td>\n",
       "      <td>Smoothie</td>\n",
       "      <td>Cold</td>\n",
       "      <td>03/03/2023</td>\n",
       "      <td>13:00</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>6.74</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1075</td>\n",
       "      <td>Smoothie</td>\n",
       "      <td>Cold</td>\n",
       "      <td>03/03/2023</td>\n",
       "      <td>13:00</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>6.74</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "2b49391d",
   "metadata": {
    "id": "2b49391d"
   },
   "source": [
    "# 3Ô∏è‚É£: Exporting the Cleaned Data\n",
    "\n",
    "Now that we have cleaned our dataset, it's important to save it for future use.  \n",
    "\n",
    "### üîπ Why Export the Data?\n",
    "- To **preserve** the cleaned version of the dataset  \n",
    "- To **avoid redoing** preprocessing steps  \n",
    "- To **use it in another project** (e.g., visualization, modeling)  \n",
    "\n",
    "We will export the dataset as a **CSV file**. Let's do it! üöÄ\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "d8608a18",
   "metadata": {
    "id": "d8608a18",
    "outputId": "5a3ecfa8-8814-4e8f-d36f-308b5d6dcc2b",
    "ExecuteTime": {
     "end_time": "2025-09-12T14:11:45.370702Z",
     "start_time": "2025-09-12T14:11:45.322910Z"
    }
   },
   "source": [
    "output_file = \"Cleaned_Restaurant_Transactions_Dataset.csv\"\n",
    "df_cleaned2.to_csv(output_file, index=False)\n",
    "print(f\"Cleaned dataset has been successfully saved to {output_file}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset has been successfully saved to Cleaned_Restaurant_Transactions_Dataset.csv\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "8953057a",
   "metadata": {
    "id": "8953057a"
   },
   "source": [
    "# Summary & Next Steps\n",
    "\n",
    "Great job! You‚Äôve successfully cleaned and prepared your dataset!\n",
    "\n",
    "### ‚úÖ What We Did:\n",
    "‚úîÔ∏è Handled missing values  \n",
    "‚úîÔ∏è Removed duplicate records  \n",
    "\n",
    "‚úîÔ∏è Exported the cleaned dataset for future use   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "31b75a7d",
   "metadata": {
    "id": "31b75a7d",
    "ExecuteTime": {
     "end_time": "2025-09-16T09:14:52.678861Z",
     "start_time": "2025-09-16T09:14:52.653482Z"
    }
   },
   "source": "",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated f-string literal (detected at line 2) (1103550778.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[6], line 2\u001B[1;36m\u001B[0m\n\u001B[1;33m    print(f\"hahash:\u001B[0m\n\u001B[1;37m          ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m unterminated f-string literal (detected at line 2)\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
